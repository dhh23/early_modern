{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# in puhti.csc.fi some of the python packages are installed under user's folder, make sure the correct \n",
    "# folder is included in the path\n",
    "\n",
    "import sys\n",
    "sys.path.append('/users/vesalaia/.local/lib/python3.9/site-packages')\n",
    "sys.path.append('/users/vesalaia/.local/lib/python3.9/site-packages/bin')\n",
    "sys.path.append('/users/vesalaia/.local/lib/python3.9/site-packages/lib/python3.9/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# detectron2 is used for object detection\n",
    "\n",
    "import detectron2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detectron2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, DatasetEvaluators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some other key libraries\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "train_dataset_name = \"Illustrations-train\"\n",
    "val_dataset_name = \"Illustrations-val\"\n",
    "\n",
    "register_coco_instances(train_dataset_name, {}, \n",
    "                        \"/scratch/project_2005488/DHH23/Illustrations/train/result.json\", \n",
    "                        \"/scratch/project_2005488/DHH23/Illustrations/train\")\n",
    "register_coco_instances(val_dataset_name, {}, \n",
    "                        \"/scratch/project_2005488/DHH23/Illustrations/test/result.json\", \n",
    "                        \"/scratch/project_2005488/DHH23/Illustrations/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/users/vesalaia/cocoapi/PythonAPI/pycocotools')\n",
    "sys.path.append('/users/vesalaia/vision/references/detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some conversions between PIL and cv2 images\n",
    "\n",
    "def convert_from_cv2_to_image(img: np.ndarray) -> Image:\n",
    "    # return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def convert_from_image_to_cv2(img: Image) -> np.ndarray:\n",
    "    # return cv2.cvtColor(numpy.array(img), cv2.COLOR_RGB2BGR)\n",
    "    return np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(DatasetCatalog.get(train_dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DatasetCatalog.get(val_dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get(train_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MetadataCatalog.get(train_dataset_name).thing_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Elementclasses = {\"Illustration - frontispiece\":1 , \"Illustration - woodcut or engraving\":2, \"Illustration - other\":3 }\n",
    "Elementclasses = {}\n",
    "for idx, val in enumerate(MetadataCatalog.get(train_dataset_name).thing_classes):\n",
    "    Elementclasses[val] = idx\n",
    "\n",
    "UNKNOWN = len(Elementclasses)-1\n",
    "\n",
    "ElementclassLabels = [x for x in Elementclasses.keys()]\n",
    "reverse_Elementclass = {v:k for k,v in Elementclasses.items()}\n",
    "def get_key(l):\n",
    "    return reverse_Elementclass[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(dataset_name, n=1):\n",
    "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
    "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
    "   \n",
    "    for s in random.sample(list(dataset_custom), n):\n",
    "        print(s['file_name'], s['image_id'])\n",
    "        img = cv2.imread(s['file_name'])\n",
    "        v = Visualizer(img[:,:,::-1], metadata=dataset_custom_metadata, scale=0.5)\n",
    "        v = v.draw_dataset_dict(s)\n",
    "        plt.figure(figsize=(15,20))\n",
    "        plt.imshow(v.get_image())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_samples(train_dataset_name,n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.data import detection_utils as utils\n",
    "import detectron2.data.transforms as T\n",
    "import copy\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    transform_list = [\n",
    "        T.Resize((800,600)),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3),\n",
    "        T.RandomSaturation(0.8, 1.4),\n",
    "        T.RandomLighting(0.7),\n",
    "    ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        coco_evaluator = COCOEvaluator(dataset_name, output_dir=output_folder)\n",
    "        evaluator_list = [coco_evaluator]\n",
    "        return DatasetEvaluators(evaluator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config_file_path = \"/scratch/project_2005488/DHH23/config.yaml\"\n",
    "\n",
    "num_classes = len(ElementclassLabels)\n",
    "device = \"cuda\"\n",
    "output_dir = \"/scratch/project_2005488/DHH23/model\"\n",
    "\n",
    "def get_train_cfg(config_file_path, train_dataset_name, num_classes, device, output_dir):\n",
    "\n",
    "    \n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file_path)\n",
    "    cfg.MODEL.WEIGHTS = \"/scratch/project_2005488/DHH23/model_final.pth\"\n",
    "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "    cfg.DATASETS.TEST = (val_dataset_name,)\n",
    "    cfg.TEST.EVAL_PERIOD =  1000\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.001\n",
    "    cfg.SOLVER.MAX_ITER = 20000\n",
    "    cfg.SOLVER.STEPS = []\n",
    "    \n",
    "#    cfg.TEST.EVAL_PERIOD = 100\n",
    "    cfg.DETECTIONS_PER_IMAGE = 100\n",
    "\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50\n",
    "    cfg.MODEL.DEVICE = device\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    cfg.MASK_FORMAT = \"bitmask\"\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = get_train_cfg(config_file_path, train_dataset_name,  num_classes, device, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import detectron2.data.transforms as T\n",
    "import copy\n",
    "\n",
    "def custom_mapper(dataset_dict):\n",
    "    \n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    transform_list = [T.Resize((800,800)),\n",
    "                      T.RandomBrightness(0.9, 1.1)]\n",
    "            \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict\n",
    "class AugTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = DefaultTrainer(cfg)\n",
    "#trainer = AugTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def on_image(image_path, predictor):\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:,:,::-1], metadata = {}, scale=0.5, instance_mode = ColorMode.SEGMENTATION)\n",
    "    v = v.draw_instance_predictions(outputs['instances'].to(\"cpu\"))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.imshow(v.get_image())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drawBoxes(image_path, predictor):\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(\n",
    "        im[:, :, ::-1], \n",
    "        metadata={}, \n",
    "        scale=0.5,\n",
    "        )\n",
    "    for box,l,sc in zip(outputs[\"instances\"].pred_boxes.to('cpu'),outputs[\"instances\"].pred_classes.to('cpu'),outputs[\"instances\"].scores.to('cpu')) :\n",
    "        \n",
    "        if sc >= 0.5 and l in [1,2,3]:\n",
    "            v.draw_box(box)\n",
    "            v.draw_text(get_key(l.item()), tuple(box[:2].numpy()))\n",
    "    v = v.get_output()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.imshow(v.get_image())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "cfg = get_train_cfg(config_file_path, train_dataset_name,  num_classes, device, output_dir)\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_TRESH_TEST = 0.8\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Call the COCO Evaluator function and pass the Validation Dataset\n",
    "evaluator = COCOEvaluator(val_dataset_name, cfg, False, output_dir=\"/scratch/project_2005488/DHH23/Illustrations/results\")\n",
    "val_loader = build_detection_test_loader(cfg, val_dataset_name)\n",
    "\n",
    "#Use the created predicted model in the previous step\n",
    "inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagedir = \"/scratch/project_2005488/DHH23/Test\"\n",
    "imagelist = os.listdir(imagedir)\n",
    "for imgname in imagelist:\n",
    "    if imgname.endswith(\".png\") or imgname.endswith(\".jpg\") or imgname.endswith(\".jpeg\"):\n",
    "        print(imgname)\n",
    "        image_path = os.path.join(imagedir,imgname)\n",
    "        drawBoxes(image_path, predictor)\n",
    "#        on_image(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
